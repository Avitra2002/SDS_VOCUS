{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Feedback                 Product\n",
      "0    Please elaborate on why you have selected trm ...  Wealth Managers Wealth\n",
      "1    Please elaborate on why you have selected trm ...  Wealth Managers Wealth\n",
      "2    Please elaborate on why you have selected trm ...  Wealth Managers Wealth\n",
      "3    Please elaborate on why you have selected trm ...  Wealth Managers Wealth\n",
      "4    Please elaborate on why you have selected trm ...  Wealth Managers Wealth\n",
      "..                                                 ...                     ...\n",
      "947  Please elaborate on why you have selected [QID...               Insurance\n",
      "948  Please elaborate on why you have selected [QID...               Insurance\n",
      "949  Please elaborate on why you have selected [QID...               Insurance\n",
      "950  Please elaborate on why you have selected [QID...               Insurance\n",
      "951  Please elaborate on why you have selected [QID...               Insurance\n",
      "\n",
      "[952 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/joel/Desktop/SUTD /T5/SDS/MY OWN DATA/combined_datanewww.csv'\n",
    "df= pd.read_csv(path)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'than', \"wouldn't\", 'so', 'before', 'who', 'while', \"you'll\", 'because', 'further', 'only', 'does', 'now', 'didn', 'ma', 'those', 'himself', 'most', \"you've\", 'be', 'few', \"aren't\", 'there', 'against', \"mightn't\", \"shouldn't\", 'all', \"shan't\", 'will', 've', 'its', 'you', \"mustn't\", 'some', 'from', 're', 'during', 'having', 'of', 'between', 'she', \"haven't\", 'his', 'both', 'yourselves', 'above', 'wasn', 'myself', 'too', 'ourselves', 'have', 'is', 'on', 'him', 'why', 'own', 'that', 'at', 'an', \"it's\", 'for', 'o', 'y', 'theirs', 'shan', 'no', 'the', 'should', 'same', 'herself', 'ain', 'i', 'hadn', 'ours', \"hasn't\", 'by', 'down', 'her', 'which', 'themselves', 'each', 'did', 'very', 'mustn', 'haven', \"won't\", 'to', 'd', 'me', 'any', 'we', 'my', 's', 'whom', 'how', 'don', 'our', \"wasn't\", 'then', 'won', 'and', \"she's\", 'such', 'these', 'mightn', 'had', 'them', 'as', 'through', 'hasn', 'off', 'shouldn', 'what', 'under', 'your', \"couldn't\", 'it', 'am', 'about', 'couldn', 'itself', 'their', 'were', 'if', 'needn', 'not', 'into', 'has', \"isn't\", 'being', 'just', 'when', 'yours', 'm', 'more', \"didn't\", 'this', \"doesn't\", 'can', 'up', 't', 'other', \"hadn't\", 'doesn', 'll', 'he', 'a', 'but', 'are', 'aren', \"don't\", 'doing', 'until', 'where', \"you'd\", 'or', 'they', 'over', 'weren', 'after', \"should've\", 'wouldn', 'nor', \"you're\", 'was', 'here', 'yourself', 'been', \"needn't\", 'with', 'in', 'out', 'below', 'isn', 'again', \"weren't\", 'once', 'do', \"that'll\", 'hers'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/joel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    text = ' '.join(filtered_words)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X= df['Feedback']\n",
    "y= df['Product']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train , test_size = 0.25 ,random_state=42,shuffle=True)\n",
    "X_train = X_train.apply(clean_text)\n",
    "X_val = X_val.apply(clean_text)\n",
    "X_test = X_test.apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9947643979057592\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                  Cards       1.00      1.00      1.00        20\n",
      "              Insurance       1.00      1.00      1.00         6\n",
      "          Secured Loans       0.98      1.00      0.99        59\n",
      "       Trading Platform       1.00      1.00      1.00         8\n",
      "        Unsecured Loans       1.00      0.88      0.93         8\n",
      "Wealth Managers Retail        1.00      1.00      1.00        38\n",
      " Wealth Managers Wealth       1.00      1.00      1.00        52\n",
      "\n",
      "               accuracy                           0.99       191\n",
      "              macro avg       1.00      0.98      0.99       191\n",
      "           weighted avg       0.99      0.99      0.99       191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_val)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                  Cards       0.10      0.10      0.10        20\n",
      "              Insurance       0.00      0.00      0.00         6\n",
      "          Secured Loans       0.27      0.24      0.25        59\n",
      "       Trading Platform       0.00      0.00      0.00         8\n",
      "        Unsecured Loans       0.00      0.00      0.00         8\n",
      "Wealth Managers Retail        0.23      0.24      0.23        38\n",
      " Wealth Managers Wealth       0.23      0.21      0.22        52\n",
      "\n",
      "               accuracy                           0.19       191\n",
      "              macro avg       0.12      0.11      0.12       191\n",
      "           weighted avg       0.20      0.19      0.19       191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_val, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5012c224380e9e16ac3aa776ebb2214372cc19954b6a7a1db6286bea1e08b097"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
