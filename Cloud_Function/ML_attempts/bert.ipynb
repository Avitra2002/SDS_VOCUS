{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/joel/Desktop/SUTD /T5/SDS/NEW OWN DATA/combined w products.xlsx'\n",
    "df=pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"doesn't\", 'off', 'its', 'was', 'haven', 'y', 'whom', 'this', 's', 'isn', 'our', 'is', 'has', 'any', 'couldn', 'yours', 'from', 'we', 'if', 'yourselves', 'no', 'them', 'up', 'which', 'when', 'themselves', \"wouldn't\", 'not', 'why', 'into', 're', 'in', \"it's\", 'i', 'how', 'will', 'yourself', 'being', 'hadn', 'such', 'these', 'under', \"isn't\", 'have', 'am', 'my', 'be', 'after', 'over', 'won', \"wasn't\", 'who', 'doing', 'll', 'but', 'don', 'been', \"hasn't\", \"couldn't\", 'other', 'the', 'what', 'during', 'more', 'ain', \"that'll\", 'her', \"she's\", 'again', 'it', 'here', 'few', 'itself', 'down', 'hasn', 'mightn', \"haven't\", 'myself', 'your', 'were', \"you'll\", 'did', 'an', 'to', 'there', 'should', \"should've\", 'most', 'just', 'himself', \"mustn't\", 'she', 'before', 'at', 'hers', \"aren't\", \"hadn't\", 'm', 'weren', \"you've\", \"you'd\", 'all', 'shouldn', 'needn', 'through', 'me', 'only', 'of', 'further', 'above', 'd', 'very', 'they', 'and', 'as', 'ours', 'with', 'having', 'too', 't', 'once', 'ma', 'are', 'nor', 'for', 'between', 'on', 'out', 'didn', 'does', 'wasn', 'some', 'had', \"didn't\", 'each', 'now', 'him', 'against', \"shan't\", 'until', 'then', 'where', 'can', 'he', 'do', 'shan', 'own', 'those', \"you're\", 'by', \"shouldn't\", 'ourselves', 'o', 'or', 'herself', 'a', 'about', 'while', 'same', \"don't\", 'that', 'doesn', 'because', \"won't\", 'below', 'theirs', 've', 'aren', \"mightn't\", 'you', 'their', \"weren't\", 'so', 'both', \"needn't\", 'wouldn', 'his', 'than', 'mustn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/joel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna(subset=['Q2b', 'Products'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# X= df['Q2b']\n",
    "# y=df['Products']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(935, 9)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Step 6: Evaluate the model\n",
    "# # Evaluate on validation set\n",
    "# y_val_pred = clf.predict(X_val)\n",
    "# val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "# print(f'Validation Accuracy: {val_accuracy:.2f}')\n",
    "\n",
    "# # Evaluate on test set\n",
    "# y_val_pred = clf.predict(X_val)\n",
    "# test_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "# print(f'Test Accuracy: {test_accuracy:.2f}')\n",
    "\n",
    "# # If you have feature importance to display\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# feature_importances = clf.feature_importances_\n",
    "# features = X.columns\n",
    "# indices = feature_importances.argsort()\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.title('Feature Importances')\n",
    "# plt.barh(range(len(indices)), feature_importances[indices], align='center')\n",
    "# plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "# plt.xlabel('Relative Importance')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae1f007525945c8b5f16aff0e460e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fd1be34385476cbab5e2bcacd9d513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bddfc566240f4577af5d6268753a764b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1238aa06549141d8919c2abc3097a3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/joel/opt/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a572e751539b49458463a497042a4830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/joel/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "----------\n",
      "Average training loss: 1.78\n",
      "Validation Accuracy: 0.62\n",
      "Epoch 2/4\n",
      "----------\n",
      "Average training loss: 1.22\n",
      "Validation Accuracy: 0.63\n",
      "Epoch 3/4\n",
      "----------\n",
      "Average training loss: 0.97\n",
      "Validation Accuracy: 0.64\n",
      "Epoch 4/4\n",
      "----------\n",
      "Average training loss: 0.76\n",
      "Validation Accuracy: 0.73\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: 'fine_tuned_bert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 128\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Save the fine-tuned model\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfine_tuned_bert\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Load and evaluate on the test set\u001b[39;00m\n\u001b[1;32m    131\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/modeling_utils.py:2440\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   2437\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProvided path (\u001b[39m\u001b[39m{\u001b[39;00msave_directory\u001b[39m}\u001b[39;00m\u001b[39m) should be a directory, not a file\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2438\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m-> 2440\u001b[0m os\u001b[39m.\u001b[39;49mmakedirs(save_directory, exist_ok\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   2442\u001b[0m \u001b[39mif\u001b[39;00m push_to_hub:\n\u001b[1;32m   2443\u001b[0m     commit_message \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mcommit_message\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: 'fine_tuned_bert'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df['Q2b']  \n",
    "y = df['Products'] \n",
    "\n",
    "X = X.replace(['NIL', 'n/a', 'na'], np.nan)\n",
    "df_clean = pd.DataFrame({'Q2b': X, 'Products': y}).dropna(subset=['Q2b', 'Products'])\n",
    "\n",
    "X = df_clean['Q2b']\n",
    "y = df_clean['Products']\n",
    "\n",
    "X = X.astype(str)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in X:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(y_encoded)\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels = len(label_encoder.classes_),\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "epochs = 4\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Average training loss: {avg_train_loss:.2f}')\n",
    "\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        predictions.extend(torch.argmax(logits, axis=1).tolist())\n",
    "        true_labels.extend(b_labels.tolist())\n",
    "\n",
    "    val_accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f'Validation Accuracy: {val_accuracy:.2f}')\n",
    "\n",
    "model.save_pretrained('fine_tuned_bert')\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size)\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predictions.extend(torch.argmax(logits, axis=1).tolist())\n",
    "    true_labels.extend(b_labels.tolist())\n",
    "\n",
    "test_accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = '//Users/joel/Downloads/glove/glove.6B.100d.txt' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5012c224380e9e16ac3aa776ebb2214372cc19954b6a7a1db6286bea1e08b097"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
